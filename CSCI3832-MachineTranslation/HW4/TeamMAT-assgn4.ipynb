{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSCI3832 - HW4 NER <br>\n",
    "Matthew Donovan, Alison Ostlund, and Thadeus Labuszewski <br>\n",
    "Team MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add clumn to test set to properly use load_conll\n",
    "def add_dummy_column(file):\n",
    "    newfile = open(\"testset.txt\", \"w\")\n",
    "    with open(file) as openfileobject:\n",
    "        for line in openfileobject:\n",
    "            if line == \"\\n\":\n",
    "                newfile.write(\"\\n\")\n",
    "            else:\n",
    "                newfile.write(line[:-1]+\"\\tD\\n\")\n",
    "    newfile.close()\n",
    "\n",
    "add_dummy_column(\"F18-assgn4-test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Loading training data... 13796 sequences, 386201 tokens.\n",
      "Loading test data... 115 sequences, 3104 tokens.\n",
      "Training StructuredPerceptron(decode='viterbi', lr_exponent=0.1, max_iter=5,\n",
      "           random_state=None, trans_features=False, verbose=True)\n",
      "Iteration  1... loss = 0.1018\n",
      "Iteration  2... loss = 0.0749\n",
      "Iteration  3... loss = 0.0641\n",
      "Iteration  4... loss = 0.0570\n",
      "Iteration  5... loss = 0.0516\n",
      "Done...IOB predicted tagging written to 'results.txt' in your directory.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import fileinput\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "from seqlearn.datasets import load_conll\n",
    "from seqlearn.evaluation import bio_f_score\n",
    "from seqlearn.perceptron import StructuredPerceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Recognition features: \n",
    "#lowercase, uppercase, number, dash, previous word(i-1)/word(i-2) and next word(i+1)/word(i+2)\n",
    "def features(sentence, i):\n",
    "    line = sentence[i]\n",
    "    word = line.split('\\t')\n",
    "    yield \"word:{}\" + str(word[1]).lower()\n",
    "\n",
    "    \n",
    "    if word[1].isupper():\n",
    "        yield \"CAP\"\n",
    "    if word[1].islower():\n",
    "        yield \"LOWER\"\n",
    "    if word[1].isnumeric():\n",
    "        yield \"NUM\"\n",
    "    if word[1] == '-':\n",
    "        yield \"DASH\"  \n",
    "\n",
    "    if i > 1:\n",
    "        yield \"word-1:{}\" + str(sentence[i - 1].split(\"\\t\")[1]).lower()\n",
    "        if word[-1].isupper():\n",
    "            yield \"PREV CAP\"\n",
    "        if word[-1] == '-':\n",
    "            yield \"DASH\" \n",
    "\n",
    "        if i > 1:\n",
    "            yield \"word-2:{}\" + str(sentence[i - 2].split(\"\\t\")[1]).lower()\n",
    "            yield \"word-2:{}\" + str(sentence[i - 2].split(\"\\t\")[1]).upper()\n",
    "\n",
    "    if i + 1 < len(sentence):\n",
    "        yield \"word+1:{}\" + str(sentence[i + 1].split(\"\\t\")[1]).lower()\n",
    "        if word[+1].isupper():\n",
    "            yield \" NEXT CAP\"\n",
    "        if word[+1] == '-':\n",
    "            yield \"DASH\" \n",
    "\n",
    "        if i + 2 < len(sentence):\n",
    "            yield \"word+2:{}\" + str(sentence[i + 2].split(\"\\t\")[1]).lower()\n",
    "            yield \"word+2:{}\" + str(sentence[i + 2].split(\"\\t\")[1]).upper()\n",
    "\n",
    "\n",
    "def describe(X, lengths):\n",
    "#Function that gives us a rough idea of what our data looks like, number of sequences(senetneces) and tokens(words)\n",
    "    print(\"{0} sequences, {1} tokens.\".format(len(lengths), X.shape[0]))\n",
    "\n",
    "    \n",
    "def load_data():\n",
    "    #Use this to load in our data so that we can pass it in to some machine learning algorithm\n",
    "    #We return a training data set and a test data set\n",
    "    print(\"Loading training data...\", end=\" \")\n",
    "    train = load_conll(fileinput.input(\"gene-trainF18.txt\"), features)\n",
    "    X_train, _, lengths_train = train\n",
    "    describe(X_train, lengths_train)\n",
    "    \n",
    "    print(\"Loading test data...\", end=\" \")\n",
    "    test = load_conll(fileinput.input(\"test-run-test-with-keys.txt\"), features)\n",
    "    X_test, _, lengths_test = test\n",
    "    describe(X_test, lengths_test)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(__doc__)\n",
    "    #load our training and test data, seqlearn has a function load_conll that makes it easy for us\n",
    "    train, test = load_data()\n",
    "    X_train, y_train, lengths_train = train\n",
    "    X_test, y_test, lengths_test = test\n",
    "\n",
    "    #train a model\n",
    "    #This implements the averaged structured perceptron algorithm of Collins and DaumÃ©, \n",
    "    #with the addition of an adaptive learning rate.\n",
    "    clf = StructuredPerceptron(verbose=True, max_iter=5)\n",
    "    print(\"Training %s\" % clf)\n",
    "    clf.fit(X_train, y_train, lengths_train)\n",
    "    \n",
    "    #extract predicted IOB labels for our X_test\n",
    "    y_pred = clf.predict(X_test, lengths_test)\n",
    "   \n",
    "    #write labels to our file so we can compare with golden standard\n",
    "    f2 = open('results.txt', 'w')\n",
    "    i = 0\n",
    "    with open('test-run-test-with-keys.txt') as openfileobject:\n",
    "        for line in openfileobject:\n",
    "            if (line == '\\n'):\n",
    "                f2.write(\"\\n\")\n",
    "            else:\n",
    "                line=line.replace(line[len(line)-2:-1], str(y_pred[i]))\n",
    "                f2.write(line)\n",
    "                i = i+1       \n",
    "    openfileobject.close()\n",
    "    f2.close()\n",
    "    \n",
    "    print(\"Done...IOB predicted tagging written to 'results.txt' in your directory.\")\n",
    "    \n",
    "    #print(\"Accuracy: %.3f\" % (100 * accuracy_score(y_test, y_pred)))\n",
    "    #print(\"CoNLL F1: %.3f\" % (100 * bio_f_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
